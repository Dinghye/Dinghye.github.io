---
title: 【技术哲学】(Part2) NOOSCOPE：AI--知识提取主义的工具

tags:
- 技术哲学
- 人工智能
categories:
- - 哲学
  - 流派
---

> The rise of AI statistical models as instruments of  knowledge . A diagram of machine learning errors, biases and limitations

作为知识工具的人工智能统计模型的兴起，机器学习的错误、偏差和局限性示意图（理解框架）

<!--more-->

上一篇地址：[(Part1) NOOSCOPE：AI--知识提取主义的工具](https://dinghye.gitee.io/2021/02/04/NOOSCOPE1/)

![NOOSCOPE MODEL APPLICATION](https://i.loli.net/2021/02/04/uBqFf2w7cW8SAH1.jpg)

# 5. 学习算法：将世界压缩成统计模型

AI的算法通常被称为炼金术公式，能够提炼出“外星人”形式的智力。但是，机器学习的算法到底如何工作的呢？包括AGI（人工智能）的追随者在内的很少有人会问这个问题。

算法是过程的名称，机器通过该过程执行计算。这种机器过程的产物是一个统计模型（更准确地称为“算法统计模型”）。在开发人员社区中，术语“算法”越来越多地由“模型”代替。这种术语上的混淆是由于统计模型与算法并没有分开存在：

> 以某种方式，统计模型以分布在整个参数上的内存形式存在于算法内部。出于同样的原因，像简单的数学函数那样，基本上不可能可视化算法统计模型。

尽管如此，挑战仍然值得。



在机器学习中，有许多**算法体系结构**：简单的感知器，深度神经网络，支持向量机，贝叶斯网络，马尔可夫链，自动编码器，玻尔兹曼机等。这些体系结构都有不同的历史（通常植根于军事机构和公司）全球北部）。人工神经网络从简单的计算结构开始，演变为复杂的结构，现在由表达数百万个**参数**的一些**超参数控制**。

例如，卷积神经网络由有限的超参数集（层数，每层神经元数，连接类型，神经元行为等）描述，这些超参数投影了数以千计的参数的数千个人工神经元的复杂拓扑之和。该算法以空白状态开始，在称为训练或“从数据中学习”的过程中，将调整其参数，直到达到输入数据的良好表示。如前所述，在图像识别中，数百万个参数的计算必须解析为简单的二进制输出：1 = true，识别出给定图像；或0 = false，则无法识别给定图像。

<img src="https://nooscope.ai/img/Nooscope_04%20Architecture.svg" alt="资料来源：https://www.asimovinstitute.org/neural-network-zoo" style="zoom: 80%;" />

尝试对算法与模型之间的关系进行易于理解的解释，让我们看一下复杂的Inception v3算法，这是一种深度卷积神经网络，用于图像识别，由Google设计并在ImageNet数据集上进行了训练。据说Inception v3在识别图片标签方面具有78％的准确性，但是在这种情况下，“机器智能”的性能也可以通过训练数据的大小与训练后的算法（或模型）之间的比例来衡量。

ImageNet包含1400万张带有相关标签的图像，这些标签占用了大约150 GB的内存。另一方面，用于表示ImageNet中包含的信息的Inception v3只有92兆字节。训练数据和模型之间的**压缩比还部分描述了信息衍射的速率**。这是一种野蛮但有效的方式来显示模型与数据之间的关系，以显示开发人员社区中如何测量和评估算法的“智能”。



**Documentation for individual models（*Source:* [keras.io/applications](https://keras.io/applications)）**

| Model             | Size   | Top-1 Accuracy | Top-5 Accuracy | Parameters  | Depth |
| ----------------- | ------ | -------------- | -------------- | ----------- | ----- |
| Xception          | 88 MB  | 0.790          | 0.945          | 22,910,480  | 126   |
| VGG16             | 528 MB | 0.713          | 0.901          | 138,357,544 | 23    |
| VGG19             | 549 MB | 0.713          | 0.900          | 143,667,240 | 26    |
| ResNet50          | 98 MB  | 0.749          | 0.921          | 25,636,712  | -     |
| ResNet101         | 171 MB | 0.764          | 0.928          | 44,707,176  | -     |
| ResNet152         | 232 MB | 0.766          | 0.931          | 60,419,944  | -     |
| ResNet50V2        | 98 MB  | 0.760          | 0.930          | 25,613,800  | -     |
| ResNet101V2       | 171 MB | 0.772          | 0.938          | 44,675,560  | -     |
| ResNet152V2       | 232 MB | 0.780          | 0.942          | 60,380,648  | -     |
| InceptionV3       | 92 MB  | 0.779          | 0.937          | 23,851,784  | 159   |
| InceptionResNetV2 | 215 MB | 0.803          | 0.953          | 55,873,736  | 572   |
| MobileNet         | 16 MB  | 0.704          | 0.895          | 4,253,864   | 88    |
| MobileNetV2       | 14 MB  | 0.713          | 0.901          | 3,538,984   | 88    |
| DenseNet121       | 33 MB  | 0.750          | 0.923          | 8,062,504   | 121   |
| DenseNet169       | 57 MB  | 0.762          | 0.932          | 14,307,880  | 169   |
| DenseNet201       | 80 MB  | 0.773          | 0.936          | 20,242,984  | 201   |
| NASNetMobile      | 23 MB  | 0.744          | 0.919          | 5,326,716   | -     |
| NASNetLarge       | 343 MB | 0.825          | 0.960          | 88,949,818  | -     |

统计模型一直影响着文化和政治。它们不仅出现在机器学习中：机器学习只是使统计建模技术自动化的一种新方法。当Greta Thunberg警告“Listen to Science”时，她真正的意思是“Listen to the statistical  models of climates science”。没有统计模型，没有气候科学：没有气候科学，没有气候行动主义。为了理解统计模型，气候科学确实是一个很好的例子。通过首先在一年中的每一天从地球表面收集大量的温度数据，然后通过应用数学模型绘制过去的温度变化曲线并将未来的模式预测出来，来计算全球变暖。气候模型是历史文物，在**科学界**内以及今天甚至以后都经过了测试和辩论。

相反，机器学习模型是不透明的，社区辩论无法讨论。考虑到围绕其数学构造的神话化程度和社会偏见，人工智能确实开启了*统计科幻小说*的时代。Nooscope是这个大型统计电影院的放映机。



# 6. 所有的模型都是错误的，但是有些是有用的

> All models are wrong, but some are useful

英国统计学家乔治·博克斯（George Box）的经典格言长期以来就封装了统计学和机器学习的逻辑局限性。

但是，这种格言通常用于使AI的偏见合法化。计算机科学家认为，人类的认知反映了抽象和近似模式的能力。那么，近似的机器做同样的事情有什么问题呢？在这个论点中，有句口头的重复说“地图不是领土(the map is not the territory)”。听起来很合理。但是应该引起争议的是，人工智能是领土的高度压缩和扭曲的地图，并且该地图与许多自动化形式一样，不接受社区谈判。AI是未经社区访问和社区同意的领土地图。

## 6.1 机器学习的抽象方法

机器学习如何绘制世界统计图？让我们看看图像识别的特殊情况（**感知工作**的基本形式，它已被编码并自动化为模式识别）。给定要分类的图像，该算法将对象的边缘检测为被亮像素包围的暗像素（典型的视觉图案）的统计分布。该算法不知道图像是什么，不像人类认知那样感知图像，它仅计算像素，亮度和接近度的数值。该算法已编程为仅记录配置文件的暗边缘（即*适合*所需的图案），而不记录图像上的所有像素（这将导致*过度拟合）*并重复整个视野）。据说统计模型可以很好地仅**适合**训练数据的重要模式，并且可以将这些模式也应用到“野外”的新数据中，因此可以成功训练。如果模型对训练数据学习得太好，则只能识别原始模式的精确匹配，而会忽略那些“非常相似”的相似模式。在这种情况下，该模型**过度拟合**，因为它已精心学习了所有内容（包括噪声），并且无法将图案与背景区别开来。另一方面，该模型不**适合**当它无法从训练数据中检测出有意义的模式时。数据过拟合，拟合和欠拟合的概念可以在笛卡尔平面上可视化。

<img src="https://nooscope.ai/img/Nooscope_06%20Approximation.svg" alt="Approximation" style="zoom: 50%;" />

维护机器学习准确性的挑战在于校准数据拟合不足和拟合过度之间的平衡，由于不同的机器偏差，很难做到这一点。机器学习是一个与“ AI”一样人性化的技术术语：

> 机器学习*无法*像人类一样正确地学习单词。机器学习仅绘制数值的统计分布图，并绘制出希望逼近人类理解力的数学函数。就是说，因此，机器学习可以为人们的理解方式提供新的思路。

从某种意义上讲，机器学习算法的统计模型也是一个近似值，它可以猜测数据图的缺失部分：通过**插值**，即在训练数据集中输入*x*的已知间隔内对输出*y*的预测，或通过**外推法，**即对输出*y*的预测超出*x*的极限，通常存在不准确的高风险。这就是今天“智能”在机器智能中的含义：将非线性函数外推到已知数据范围之外。正如Dan McQuillian恰当地指出的那样：

> “人工智能中没有智能，也没有学习能力，即使其技术名称是机器学习，也只是数学上的最小化。”

重要的是要记住，机器学习的"智能"不是由精确的数学分析公式驱动，而是由**蛮力逼近**算法驱动。输入*x*和输出*y*之间的相关函数的形状是通过逐步调整的累赘机械过程（例如，类似于梯度下降）通过算法逐步计算的，这些过程等效于莱布尼兹和牛顿的微积分。据说神经网络是最有效的算法之一，因为如果有足够的神经元层和足够的计算资源，这些差分方法可以*近似*任何函数的形状。有效的蛮力渐进逼近是当今AI的核心特征，只有从这一角度来看，人们才能了解其潜力和局限性-特别是其不断扩大的carbon footprint（深度神经网络的训练由于梯度下降而需要大量的能量）以及基于连续无穷小调整的类似训练算法。



# 7. 从世界到矢量

数据拟合，过度拟合，拟合不足，内插和外推的概念可以在二维中轻松显示，但统计模型通常沿数据的多维空间运行。在进行分析之前，将数据编码到远非直观**的多维向量空间**中。向量空间是什么，为什么它是多维的？Cardon，Cointet和Mazière用以下方式描述了数据的向量化：

> 神经网络要求计算器的输入采用向量的形式。因此，必须预先以纯数字矢量表示的形式对世界进行编码。尽管某些对象（例如图像）自然地分解为矢量，但其他对象需要"嵌入embedded"在矢量空间中，然后才能使用神经网络对其进行计算或分类。
>
> 文本就是这种情况，这是典型的例子。要将单词输入到神经网络中，*Word2vec*技术将其“嵌入”到一个向量空间中，该空间可测量其与语料库中其他单词的距离。因此，单词继承了具有数百个维度的空间内的位置。这种表示的优点在于这种转换提供的众多操作。在此空间中推断位置彼此接近的两个术语在语义上同样相似。这些表示被认为是分布式的：概念“公寓”的向量[-0.2、0.3，-4.2、5.1 ...]将类似于“房子”的向量[-0.2、0.3，-4.0、5.1。 ..]。虽然自然语言处理在向量空间中“嵌入”单词方面开创了先河，但如今，我们正在见证对嵌入过程的概括，该过程正在逐步扩展到所有应用领域：*graph2vec*，带有段落vec的文本，带有*movie2vec的*电影，具有*sens2vec*的单词的含义，具有*mol2vec的*分子结构等。根据Yann LeCun*所说*，连接主义机器的设计者的目标是将世界置于向量中（*world2vec*）。



**多维向量空间**是机器学习逻辑难以掌握的另一个原因。向量空间是另一种新的文化技术，值得熟悉。尤其是数字人文科学领域，已经涵盖了矢量化技术，通过这种技术，我们的集体知识得以无形地呈现和处理。威廉·吉布森（William Gibson）最初对网络空间的定义预示了矢量空间而非虚拟现实的出现

> 从人类系统中每台计算机的数据库抽象出来的数据的图形表示。难以想象的复杂性。光线分布在思维的非空间，数据的簇和星座中。像城市的灯光一样，渐渐退去。

![Statua citofonica(Right:Vector space of seven words in three contexts)](https://nooscope.ai/img/Nooscope_05%20Black%20Box.svg)

但是必须强调的是，机器学习仍然比精确的数学更像工艺。人工智能仍然是骇客和技巧的历史，而不是神秘的直觉。例如，信息压缩的一个窍门是降维，该降维用于避免**维数**的诅咒，即向量空间中各种特征的指数增长。在向量空间中显示出低方差（即，其值仅波动很小）的类别的维度被汇总以减少计算成本。降维可以用于聚类词义（例如在模型word2vec中），但也可以导致**类别减少（category reduction）**，这可能会影响社会多样性的表现。降维可以缩小分类法并引入偏见，从而进一步规范世界多样性并消除唯一身份。

![Dimensions](https://nooscope.ai/img/Nooscope_08%20Dimensions.svg)



# 8. The society of classification and prediction bots

可以根据分类和预测这两种模式描述机器学习在当代的大多数应用，它们概述了控制和统计治理新社会的轮廓。分类被称为*模式识别（pattern recognition），*而预测也可以定义为*模式生成（pattern generation）*。通过询问统计模型的内核，可以识别或生成新的模式。

## 8.1 分类

机器学习**分类**通常用于识别符号，对象或人脸，并根据分类法或文化习俗分配相应的类别（标签）。通过模型运行输入文件（例如，由监视摄像机捕获的头像）以确定其是否在其统计分布范围内。如果是这样，则会为其分配相应的输出标签。自Perceptron时代以来，分类一直是神经网络的原始应用：借助深度学习，在警察和智能手机制造商等部署的人脸识别分类器中普遍发现了该技术。

## 8.2 预测

机器学习**预测**用于根据过去的趋势**预测**未来的趋势和行为，即完成仅了解一部分信息的一条信息。在预测模式中，将使用少量输入数据样本（引物）来预测信息的缺失部分，以再次遵循模型的统计分布（这可能是面向未来或未来的数字图的一部分）图片或音频文件缺少部分）。顺便说一句，还存在其他机器学习模式：可以通过一种称为“潜在空间探索”的技术动态地可视化模型的统计分布，在某些最近的设计应用程序中，还可以使用*模式探索。*

## 8.3 应用

> 技术应用&分类与预测

机器学习的分类和预测正在成为构成监视和治理的新形式中无处不在的技术。某些设备（例如自动驾驶汽车和工业机器人）可以是这两种方式的集成。自动驾驶汽车经过训练可以识别道路上的不同物体（人，汽车，障碍物，标志），并根据人类驾驶员在类似情况下采取的决策来预测未来的行动。即使认识到道路上的障碍是否是中立的姿态（或者不是），也要根据性别，种族和阶级（在最近的COVID-19大流行中将其确定为疾病或免疫）来识别一个人，并将其确定为国家机构新纪律制度的基础。这一部分工作吸引力了越来越多的注意。自动分类的狂妄自大导致了反动的伦布罗亚技术（reactionary Lombrosian techniques）的复兴，这些技术被认为已经成为历史，如自动性别识别（AGR），"面部识别的一个子领域，旨在通过算法从照片或视频中识别个人的性别。

![Modes](https://nooscope.ai/img/Nooscope_05%20Modes.svg)



> 文化方面&生成神经网络

近年来，机器学习的生成方式已经产生了文化影响：大众媒体已经接受了将其用于视觉人工制品的生产，认为人工智能是“创造性的”并且可以自主地制造艺术品。但也有说法说由AI创造的艺术品总是隐藏着人类操作，该操作应用了在特定数据集上训练的神经网络的生成方式。在这种模式下，神经网络*向后*运行（从较小的输出层移向较大的输入层）以在对它们进行分类训练后生成新模式，该过程通常从较大的输入层移至较小的输出层。然而，生成模型也有一些有用的应用：它可以用作一种现实检查，以揭示模型学到的东西，即表明模型如何“看待世界”。例如，它可以应用于自动驾驶汽车的模型，以检查如何预测路况。

Google DeepDream是说明统计模型如何“看待世界”的一种著名方法。DeepDream是一个基于Inception的卷积神经网络（在上面提到的ImageNet数据集上进行了训练），该网络由Alexander Mordvintsev编程以投射幻觉模式。Mordvintsev的想法是“颠倒网络”，即使用一些随机噪声或通用风景图像作为输入，将分类器变成生成器。他发现，”经过训练以区分不同类型图像的神经网络也具有生成图像所需的大量信息。” 在DeepDream的第一个实验中，由于ImageNet中的犬种和鸟类种类过多，鸟羽毛和狗眼开始随处可见。还发现，“哑铃”类别是通过始终附有超现实的人类手臂来学习的。证明ImageNet的许多其他类别存在错误。

<img src="https://i.loli.net/2021/02/06/uUvHSQofgRJVdNx.jpg" alt="deepdream：create your nightmare" style="zoom:35%;" />

分类和生成的两种主要方式可以在进一步的体系结构中进行组合，例如在生成对抗网络中。在GAN架构中，具有*鉴别器discriminator*（传统分类器）作用的神经网络必须在增强环中识别由神经网络生成的图像，该图像同时具有*生成器generator*作用，该增强循环同时训练两个统计模型。对于其各自的统计模型的某些收敛性质，GAN已被证明非常擅长生成高度逼真的图像。这种能力促使他们滥用“deep fakes”。

关于真实的管理体系，类似的争议性应用是在癌症研究中使用GAN生成合成数据，其中在癌症组织的不平衡数据集上训练的神经网络已经开始在正常数据中检测出”错觉癌症“。在这种情况下，不是发现事物，而是发明事物”，然而Fabian Providet注意：“**发现的空间与GAN已有的知识空间相同**。虽然我们认为，我们看到通过GAN在寻找的东西，我们实际上看到GAN的内部（see into a GAN）。GAN愿景不是增强现实（augmented reality），而是虚拟现实（virtual reality）。GAN确实模糊了发现（discovery）和发明（invention）。GAN对脑癌的模拟是AI驱动的科学错觉的悲剧性例子。

![*Joseph Paul Cohen, Margaux Luck and Sina Honari. ‘Distribution Matching Losses Can Hallucinate Features in Medical Image Translation’, 2018. Courtesy of the authors.*](https://nooscope.ai/img/Nooscope-09-Tumor.gif)

（未完待续）