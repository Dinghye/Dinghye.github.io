---
title: 【连续学习】Learning without Forgetting(LwF)
tags:
  - Paper Reading
categories:
  - - 机器学习
    - 连续学习

mathjax: true
---


本部分主要给出Li和Hoiem[2016]中给出的名为*Learning without Forgetting* 的方法

<!-- more-->

## 1. 原理简介

​	本章介绍Li和Hoiem[2016]中给出的名为*Learning without Forgetting* 的方法。基于4.1节中的符号，它借助*θs*（所有任务的共享参数）和*θo*（旧任务的参数）来学习*θn*（新任务的参数），而不会降低旧任务的很多性能。其相法是在新任务上优化*θs*和*θn*，约束条件是使用θs和θo对新任务的例子的预测不会有太大的转变。这个约束条件确保了模型仍然“记得”它的就参数，目的是为了在之前的任务上保持令人满意的性能。

## 2. 算法概述    

算法概述见算法4.1。第二行用*θo*和*θs*记录新任务的例子Xn的预测Yo，这将用于目标函数（第七行）。对于每一个新任务，输出层都会增加节点，它与下面的层完全连接。这些新节点首先用随机权重*θn*初始化（第3行）。在第7行中，目标函数有三个部分。

| **Algorithm 4.1:** Learning without Forgetting               |
| ------------------------------------------------------------ |
| 输入：共享参数*θ**s**，*旧任务的任务规格参数*θo*，新任务的训练数据Xn、Yn。 <br /> 输出：更新的参数θ*s、θ*o、θ*n |
|                                                              |

1. //初始化阶段  

2.   *Yo*←CNN(*Xn**，θs**，θo*) 

3. *θn*←RANDINIT(|*θn*|)  

4. //训练阶段  

5. 定义  $\hat Y_n≡CNN(X_n,\hat θ_s,\hatθ_n )$    
   
6. 定义  $\hat Y_o≡CNN(X_n,\hat θ_s,\hatθ_n )$
   
7.   $\theta_s^,\theta_0^*,\theta_n^*←argmin{θs^*,θ_o^*,θ_n^*}(L_{new} (\hat Y_n,Y_n)+λ_0 L_{old} (\hat Y_0,Y_0 )+R(θ_s,_θ_0,θ_n ))$

* $L_{new}$: 最小化预测值  和真实值  之间的差异。其中  是使用当前参数  预测出来的值（第五行）。在Li 和Hoiem[2016]的文章中，使用的是多项式逻辑斯蒂损失：_

  ​							$L_{new} (\hat Y_n,Y_n )=-Y_n*log\hat Y_n$_

* $L_{old}$: 最小化预测值  和记录值  之间的差异（第二行）。其中  来自于当前的参数  （第六行）。Li和Hoiem[2016]使用知识蒸馏损失（knowledge distillation loss）[Hinton 等，2015]来鼓励一个网络的输出来逼近另一个网络的输出。蒸馏损失为定义为修正的交熵损失：_

  ​			$L_{old}(\hat Y_0,Y_0 )=-H(\hat Y'_0,\hat Y'_0 )=-\sum_{i=1}^by'^{(i)}_0log⁡{\hat {y'}_0^{(i)}}$

  其中l是标签的标号。最右边两个y是修改的可能性，定义为：

  ​			$y_o^{(i)}=(y_o^i)^{1/T}/{∑_j(y_o^j )^{1/T}} , \hat {y}_o^{'i}=(\hat y_o^i )^{1/T}/(\sum_j\hat y_o^j )^{1/T})$

  在Li和Hoiem[2016]中，将T设SA置为2，以增加较小的logit值的权重。在目标函数（第 7 行）中，$λ_0$用于平衡新任务和旧任务/过去任务。Li和Hoiem[2016]在实验中尝试了不同的数值。

•  *R(θs,θo,θn)*：正则化项，避免过拟合