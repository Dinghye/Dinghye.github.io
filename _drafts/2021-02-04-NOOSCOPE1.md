---
title: 【技术哲学】(Part1) NOOSCOPE：AI--知识提取主义的工具

tags:
- 技术哲学
- 人工智能
categories:
- - 哲学
  - 流派
---

> The rise of AI statistical models as instruments of  knowledge . A diagram of machine learning errors, biases and limitations

作为知识工具的人工智能统计模型的兴起，机器学习的错误、偏差和局限性示意图（理解框架）

<!--more-->

# 0. Preview

原文网站：https://nooscope.ai/

原文链接：https://link.springer.com/article/10.1007/s00146-020-01097-6

Pasquinelli, M., Joler, V. The Nooscope manifested: AI as instrument of knowledge extractivism. *AI & Soc* (2020). https://doi.org/10.1007/s00146-020-01097-6

![NOOSCOPE MODEL APPLICATION](https://i.loli.net/2021/02/04/uBqFf2w7cW8SAH1.jpg)

# 1. 什么是NOOSCOPE

Nooscope是对人工智能极限的制图，旨在激发计算机科学和人文科学，主要目的是探索AI的奥秘。它可以作为“智能（Intelligence）”的技术定义，并且可以作为社会和人类“自主（autonomous）”的政治形式。

Nooscope的目的是将AI从“智能机器”的思想状态世俗化为一种知识工具。与其唤起外星认知的传说，不如将机器学习视为一种知识放大的工具（instrument of knowledge magnification），帮助人们通过人类无法触及的巨大数据空间来感知特征、模式和相关性，这才是更合理的做法。在科学的传统中，机器学习只是Nooscope，它是一种用于观察和导航知识空间的工具。（from the Greek *skopein* ‘to examine, look’ and *noos* ‘knowledge’）

Nooscope图借鉴了Gottfried Wilhelm Leibniz的想法，将光学介质的类比应用于所有机器学习设备的结构。莱布尼兹讨论了**微积分**（calculus ratiocinator）和**特征数**（characteristic numbers）（设计数字通用语言以编纂和解决人类推理的所有问题的想法）的能力后，用显微镜和望远镜等视觉放大工具进行了类比。他写道：

> “一旦为大多数概念确定了特征数，人类将拥有一种新的仪器，它将比光学仪器增强眼睛的能力更大程度地增强心灵的能力，并将取代显微镜和望远镜到人体。理由胜过视力。” 

尽管本文的目的不是要重申定量文化和定性文化之间的对立，但莱布尼兹的信条并不一定要遵循。争议无法得出结论。机器学习不是智能的最终形式。

**测量和感知工具始终带有内置像差**。就像显微镜和望远镜的镜片永远不会完美地弯曲和平滑一样，<u>*逻辑镜片*</u>(logic lenses)机器学习体现了缺陷和偏见。理解机器学习并记录其对社会的影响，就是研究社交数据在这些方面对衍射和扭曲的程度。这通常被称为关于AI偏见的辩论，但是机器学习的逻辑形式的政治含义更深。机器学习并没有带来一个新的黑暗时代，而是<u>一个漫不经心的理性时代</u>，其中，正如将要展示的那样，因果关系的认知被自动关联之一代替。一般而言，人工智能是一种新的真理，科学证据，社会规范性和合理性制度，通常会以一种<u>*统计幻觉*</u>(statistical hallucination)的形式出现。此图宣言是另一种说法，即计算之王AI（机械知识的父权幻想，“主算法”和*alpha机器*）是赤裸裸的。

> 在这里，我们正在窥视其黑匣子。



# 2. 机器学习的流水线：Data, Algorithm,Model



## 2.1 不可解释的黑匣子

> 在发现用于解释和控制其内部工作原理的热力学定律之前，人工智能与蒸汽机发明处于同一阶段

​	人工智能的历史是实验，机器故障，学术争论，围绕军事资金的史诗般的竞争的历史，通常被称为“winters of AI”。尽管如今企业AI用“黑魔法”和“超人认知”的语言描述其功能，但当前的技术仍处于试验阶段。<u>在发现用于解释和控制其内部工作原理的热力学定律之前，人工智能与蒸汽机发明处于同一阶段。</u>同样，今天，有用于图像识别的高效神经网络，但没有***学习理论***解释为什么它们表现如此出色，以及它们如何如此严重地失败。像任何发明一样，机器学习的模式在过去的半个世纪中一直在缓慢地整合。主算法并非一朝一夕就能出现。而是逐步建立了一种计算方法，仍然必须找到一种通用语言。例如，面向学生的机器学习手册尚未共享通用术语。那么，

> 如何在不参与定义通用智能的偏执游戏的情况下，勾勒出简洁明了的机器学习关键语法呢？



## 2.2 规范化机器学习与偏见

机器学习作为一种知识手段，由观察对象（**训练数据集**），观察手段（**学习算法**）和最终表示形式（**统计模型**）组成。这三个元素的组合在这里被提出为伪巴洛克式机器学习图(spurious and baroque diagram of machine learning)，美其名曰Nooscope。

> 与光学媒体类似，机器学习的信息流就像一束光束，它是由训练数据投射，由算法压缩并由统计模型的镜头向世界传播的。

Nooscope图旨在同时说明机器学习的两个方面：**它是如何工作的以及它是如何失败的**—列举其主要成分，以及广泛的错误，限制，近似值，偏差，错误，谬论和漏洞是其范例的本机。这种双重操作强调人工智能不是理性的整体范式，而是由适应技术和技巧构成的虚假架构。此外，AI的局限性不仅是技术上的限制，而且还伴随着人为的偏见。在Nooscope图表中，机器学习的基本组成部分位于中心，**人类的偏见**和干预措施位于左侧，**技术偏见**和右边的限制。光学透镜代表代表信息流压缩和失真的偏差和近似值。机器学习的总偏差由统计模型的中心透镜表示，通过该模型可以衍射世界的感知。

如今，由于人们对偏见的讨论（即通过算法放大性别，种族，能力和阶级歧视），人们普遍意识到了AI的局限性。在机器学习中，有必要区分历史偏差，数据集偏差和算法偏差，所有这些都发生在信息流的不同阶段。在技术干预之前，**历史偏见**（或世界偏见）已在社会中显现出来。尽管如此，这种偏见的自然化**，**即将不平等默默地整合到表面上中立的技术本身是有害的。鲁哈·本杰明（Ruha Benjamin）用米歇尔·亚历山大（Michelle Alexander）的话来称呼它为“新吉姆法典”：

> “采用能反映和重现现有不平等现象，但比以前的歧视性制度更为客观和进步的新技术。”



**数据集偏差**是通过操作员准备训练数据而引入的。这个过程中最微妙的部分是数据标记，其中旧的和保守的分类法可能导致对世界的扭曲，歪曲了社会多样性并加剧了社会等级制（请参见下面的ImageNet案例）。

**算法偏差**（也称为机器偏差，统计偏差或模型偏差，Nooscope图表特别关注这些偏差）是通过机器学习算法进一步放大历史偏差和数据集偏差。偏差问题主要源于以下事实：机器学习算法是最有效的**信息压缩方法，**这会引起信息分辨率，衍射和丢失等问题。自古以来，算法一直是一种具有经济性质的程序，旨在使结果以最少的步骤消耗最少的资源（空间，时间，能源和劳动力）来实现。如今，人工智能公司的军备竞赛仍在关注寻找最简单，最快的算法来利用数据。从社会的角度来看，如果信息压缩在企业AI中产生最大的利润率，则会产生歧视和文化多样性的丧失。



## 2.3 普遍存在的黑匣子效应

虽然在偏见问题下人们普遍理解了AI的社会后果，但对技术局限性的普遍理解被称为**黑匣子**问题。黑匣子效应是深度神经网络的一个实际问题（对信息的过滤如此之大，以至于其推理链无法逆转），但已成为通用的借口，认为AI系统不仅难以理解且不透明，而且甚至是“外星人”和失控。黑匣子效应是任何实验机在开发初期阶段的一部分（已经注意到，即使在成功测试之后，蒸汽机的功能仍然是一个谜仍然存在了一段时间）。真正的问题是黑匣子言论，它与阴谋论理论紧密相关，在阴谋论理论中，人工智能是一种不可研究，不可知或无法通过政治手段控制的隐秘力量。



# 3. 训练数据集：机器智能的社会起源

大规模的数字化提供了史无前例的大量数据资源，**知识提取主义**（后称为大数据）体制通过算法在有效开放资源中提取“情报”。

## 3.1 数据集

构成AI来源的数据集是什么样的文化和技术对象？**训练数据**的质量是影响机器学习算法提取的所谓“智能”的最重要因素。为了将AI理解为Nooscope，需要考虑一个重要的观点：

> 数据是价值和智慧的第一来源。算法是第二位；它们是将这种价值和智能计算成模型的机器。但是，训练数据绝不会是原始的，独立的且没有偏见的（它们本身已经是“算法”）

训练数据集的雕刻，格式化和编辑是一项艰巨而精致的工作，对于最终结果而言，它可能比控制学习算法的技术参数更为重要。选择一个数据源而不是另一个数据源的行为是人类干预“人工”思想领域的深刻印记。

<img src="https://nooscope.ai/img/Nooscope_02%20Data.svg" alt="训练数据集是一种文化结构，而不仅仅是技术结构。它通常包含与理想输出数据相关联的输入数据，例如带有描述的图片，也称为标签或元数据。典范的例子是博物馆馆藏及其档案馆，其中的艺术品由作者，年份，媒介等元数据来组织。为图片分配名称或类别的符号过程从不公正。这个动作在机器认知的最终结果上留下了另一个深刻的人类烙印。用于机器学习的训练数据集通常通过以下步骤组成：1）生产：劳动或产生信息的现象；2）捕获：通过仪器将信息编码为数据格式：3）格式化：将数据组织为数据集：4）标记：在监督学习中，将数据分类为类别（元数据）" style="zoom: %;" />

## 3.2 数据集歧视

>机器智能是在庞大的数据集上进行训练的，这些数据集在技术上既不中立也不在社会上公正。





# 4. 人工智能作为感知自动化的历史

> 思维与模式识别？

至少在技术角度上，揭开AI神秘面纱的需要在企业界也得到理解。Facebook AI负责人和卷积神经网络教父Yann LeCun重申，当前的AI系统不是认知的复杂版本，而是<u>**感知的复杂版本**</u>。类似地，Nooscope图暴露了AI黑匣子的骨架，并表明AI并不是思维自动机，而是执行**模式识别**（pattern recognition）的算法。模式识别的概念包含必须阐述的问题。顺便问一下，什么是模式？模式是唯一的可视实体吗？将社会行为解读为模式意味着什么？模式识别是否是对智能的详尽定义？很有可能不会。为了澄清这些问题，最好对AI进行简要的考古学。

模式识别的**原型机**是Frank Rosenblatt的**Perceptron**。它于1957年在纽约布法罗的康奈尔航空实验室发明，名称是“感知和识别自动机”的简写。给定一个20x20感光器的视觉矩阵，感知器可以学习如何识别简单字母。视觉模式被记录为在人工神经元网络上的印象，这些人工神经元与相似图像的重复协同工作并激活一个输出神经元。如果识别出给定图像，则输出神经元激发为1 = true，否则为0 = false。

感知的自动化，作为一条计算流水线上像素的视觉蒙太奇(visual montage of pixels along a computational assembly line)，最初是隐含的McCulloch和Pitt的人工神经网络概念。视觉模式识别算法在“人工智能的冬天”中幸存下来并在2000年代后期证明是有效的之后，它也被应用于非视觉数据集，从而适当地开启了深度学习的时代（模式识别技术在各种类型的计算机上的应用）。数据，而不仅仅是视觉数据。如今，对于自动驾驶汽车，需要识别的模式是道路场景中的对象。在自动翻译的情况下，需要识别的模式是跨双语文本的最常见单词序列。无论它们的复杂性如何，从机器学习的数字角度来看，诸如图像，运动，形式，样式和道德决策等概念都可以描述为模式的统计分布。从这个意义上说，模式识别已真正成为一种新的在各个领域中使用的**文化技术**。为了说明起见，Nooscope被描述为以三种模式运行的机器：**训练**，**分类**和**预测**（**training**, **classification**, and **prediction**）。用更直观的术语来说，可以将这些模式称为：模式提取，模式识别和模式生成（pattern extraction, pattern recognition, and pattern generation）。

Rosenblatt的Perceptron是第一个为当代意义上的机器学习铺平道路的算法。在尚未采用“计算机科学”作为定义的时候，Rosenblatt本人将该领域称为“计算几何”，特别是“连接主义”（connectionism）。但是，这些神经网络的业务是计算统计推断。神经网络计算的不是精确的模式，而是模式的**统计分布**。只是刮开了人工智能的拟人化的面，人们发现了另一个需要检验的技术和文化对象：**统计模型**。

> 机器学习中的统计模型是什么？如何计算？统计模型和人类认知之间有什么关系？这些是需要澄清的关键问题。就需要完成的神秘化工作而言（也可以消除一些天真的问题），重新定义陈旧的问题“机器可以思考吗？”也许是一个很好的方向。在理论上更合理的问题中：“统计模型可以思考吗？”，“统计模型可以发展意识吗？”等。

---

目前人工智能的主要学派有：

**1、符号主义**

 符号主义(symbolicism)，又称为逻辑主义(logicism)、心理学派(psychologism)或计算机学派(computerism)，其原理主要为物理符号系统(即符号操作系统)假设和有限合理性原理。

认为人工智能源于**数理逻辑**。数理逻辑从19世纪末起得以迅速发展，到20世纪30年代开始用于描述智能行为。计算机出现后，又再计算机上实现了逻辑演绎系统。其有代表性的成果为启发式程序LT逻辑理论家，证明了38条数学定理，表了可以应用计算机研究人的思维多成，模拟人类智能活动。正是这些符号主义者，早在1956年首先采用“人工智能”这个术语。后来又发展了启发式算法->专家系统->知识工程理论与技术，并在20世纪80年代取得很大发展。符号主义曾长期一枝独秀，为人工智能的发展作出重要贡献，尤其是专家系统的成功开发与应用，为人工智能走向工程应用和实现理论联系实际具有特别重要的意义。在人工智能的其他学派出现之后，符号主义仍然是人工智能的主流派别。这个学派的代表任务有纽厄尔(Newell)、西蒙(Simon)和尼尔逊(Nilsson)等。

**2、连接主义**

连接主义(connectionism)，又称为仿生学派(bionicsism)或生理学派(physiologism)，其主要原理为神经网络及神经网络间的连接机制与学习算法。

认为人工智能源于**仿生学**，特别是对人脑模型的研究。它的代表性成果是1943年由生理学家麦卡洛克(McCulloch)和数理逻辑学家皮茨(Pitts)创立的脑模型，即MP模型，开创了用电子装置模仿人脑结构和功能的新途径。它从神经元开始进而研究神经网络模型和脑模型，开辟了人工智能的又一发展道路。20世纪60~70年代，连接主义，尤其是对以感知机(perceptron)为代表的脑模型的研究出现过热潮，由于受到当时的理论模型、生物原型和技术条件的限制，脑模型研究在20世纪70年代后期至80年代初期落入低潮。直到Hopfield教授在1982年和1984年发表两篇重要论文，提出用硬件模拟神经网络以后，连接主义才又重新抬头。1986年，鲁梅尔哈特(Rumelhart)等人提出多层网络中的反向传播算法(BP)算法。此后，连接主义势头大振，从模型到算法，从理论分析到工程实现，伟神经网络计算机走向市场打下基础。现在，对人工神经网络(ANN)的研究热情仍然较高，但研究成果没有像预想的那样好。

**3、行为主义**

行为主义(actionism)，又称为进化主义(evolutionism)或控制论学派(cyberneticsism)，其原理为控制论及感知-动作型控制系统。

认为人工智能源于**控制论**。控制论思想早在20世纪40-50年代就成为时代思潮的重要部分，影响了早期的人工智能工作者。维纳(Wiener)和麦克洛克(McCulloch)等人提出的控制论和自组织系统以及钱学森等人提出的工程控制论和生物控制论，影响了许多领域。控制论把神经系统的工作原理与信息理论、控制理论、逻辑以及计算机联系起来。早期的研究工作重点是模拟人在控制过程中的智能行为和作用，如对自寻优、自适应、自镇定、自组织和自学习等控制论系统的研究，并进行“控制论动物”的研制。到20世纪60-70年代，上述这些控制论系统的研究取得一定进展，播下智能控制和智能机器人的种子，并在20世纪80年代诞生了智能控制和智能机器人系统。行为主义是20世纪末才以人工智能新学派的面孔出现的，引起许多人的兴趣。这一学派的代表作者首推布鲁克斯(Brooks)的六足行走机器人，它被看作是新一代的“控制论动物”，是一个基于感知-动作模式模拟昆虫行为的控制系统。

（未完待续）